{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Using a GPU ...\n"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "DATA_DIR = \".data\"\n",
    "CHECKPOINT_DIR = os.path.join(DATA_DIR, \"checkpoints\")\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if len(gpus)>0:\n",
    "    print(\"Using a GPU ...\")\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_read(urls):\n",
    "   texts = []\n",
    "   for i, url in enumerate(urls):\n",
    "       p = tf.keras.utils.get_file(\"ex1-{:d}.txt\".format(i), url,\n",
    "           cache_dir=DATA_DIR)\n",
    "       text = open(p, \"r\").read()\n",
    "       # remove byte order mark\n",
    "       text = text.replace(\"\\ufeff\", \"\")\n",
    "       # remove newlines\n",
    "       text = text.replace('\\n', ' ')\n",
    "       text = re.sub(r'\\s+', \" \", text)\n",
    "       # add it to the list\n",
    "       texts.extend(text)\n",
    "   return texts\n",
    "texts = download_and_read([\n",
    "   \"http://www.gutenberg.org/cache/epub/28885/pg28885.txt\",\n",
    "   \"https://www.gutenberg.org/files/12/12-0.txt\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "vocab size: 89\n"
    }
   ],
   "source": [
    "# create the vocabulary\n",
    "vocab = sorted(set(texts))\n",
    "print(\"vocab size: {:d}\".format(len(vocab)))\n",
    "# create mapping from vocab chars to ints\n",
    "char2idx = {c:i for i, c in enumerate(vocab)}\n",
    "idx2char = {i:c for c, i in char2idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numericize the texts\n",
    "texts_as_ints = np.array([char2idx[c] for c in texts])\n",
    "data = tf.data.Dataset.from_tensor_slices(texts_as_ints)\n",
    "# number of characters to show before asking for prediction\n",
    "# sequences: [None, 100]\n",
    "seq_length = 100\n",
    "sequences = data.batch(seq_length + 1, drop_remainder=True)\n",
    "def split_train_labels(sequence):\n",
    "   input_seq = sequence[0:-1]\n",
    "   output_seq = sequence[1:]\n",
    "   return input_seq, output_seq\n",
    "sequences = sequences.map(split_train_labels)\n",
    "# set up for training\n",
    "# batches: [None, 64, 100]\n",
    "batch_size = 64\n",
    "steps_per_epoch = len(texts) // seq_length // batch_size\n",
    "dataset = sequences.shuffle(10000).batch(\n",
    "    batch_size, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharGenModel(tf.keras.Model):\n",
    "   def __init__(self, vocab_size, num_timesteps,\n",
    "           embedding_dim, **kwargs):\n",
    "       super(CharGenModel, self).__init__(**kwargs)\n",
    "       self.embedding_layer = tf.keras.layers.Embedding(\n",
    "           vocab_size,\n",
    "           embedding_dim\n",
    "       )\n",
    "       self.rnn_layer = tf.keras.layers.GRU(\n",
    "           num_timesteps,\n",
    "           recurrent_initializer=\"glorot_uniform\",\n",
    "           recurrent_activation=\"sigmoid\",\n",
    "           stateful=True,\n",
    "           return_sequences=True)\n",
    "       self.dense_layer = tf.keras.layers.Dense(vocab_size)\n",
    "   def call(self, x):\n",
    "       x = self.embedding_layer(x)\n",
    "       x = self.rnn_layer(x)\n",
    "       x = self.dense_layer(x)\n",
    "       return x\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "\n",
    "model = CharGenModel(vocab_size, seq_length, embedding_dim)\n",
    "model.build(input_shape=(batch_size, seq_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, predictions):\n",
    "   return tf.losses.sparse_categorical_crossentropy(\n",
    "       labels,\n",
    "       predictions,\n",
    "       from_logits=True\n",
    "   )\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, prefix_string, char2idx, idx2char,\n",
    "       num_chars_to_generate=1000, temperature=1.0):\n",
    "   input = [char2idx[s] for s in prefix_string]\n",
    "   input = tf.expand_dims(input, 0)\n",
    "   text_generated = []\n",
    "   model.reset_states()\n",
    "   for i in range(num_chars_to_generate):\n",
    "       preds = model(input)\n",
    "       preds = tf.squeeze(preds, 0) / temperature\n",
    "       # predict char returned by model\n",
    "       pred_id = tf.random.categorical(\n",
    "           preds, num_samples=1)[-1, 0].numpy()\n",
    "       text_generated.append(idx2char[pred_id])\n",
    "       # pass the prediction as the next input to the model\n",
    "       input = tf.expand_dims([pred_id], 0)\n",
    "   return prefix_string + \"\".join(text_generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train for 28 steps\nEpoch 1/10\n28/28 [==============================] - 5s 176ms/step - loss: 3.8543\nEpoch 2/10\n28/28 [==============================] - 0s 15ms/step - loss: 3.1069\nEpoch 3/10\n28/28 [==============================] - 0s 15ms/step - loss: 2.8592\nEpoch 4/10\n28/28 [==============================] - 0s 16ms/step - loss: 2.6296\nEpoch 5/10\n28/28 [==============================] - 0s 15ms/step - loss: 2.4931\nEpoch 6/10\n28/28 [==============================] - 0s 15ms/step - loss: 2.4045\nEpoch 7/10\n28/28 [==============================] - 0s 16ms/step - loss: 2.3345\nEpoch 8/10\n28/28 [==============================] - 0s 15ms/step - loss: 2.2711\nEpoch 9/10\n28/28 [==============================] - 0s 16ms/step - loss: 2.2134\nEpoch 10/10\n28/28 [==============================] - 0s 16ms/step - loss: 2.1611\nafter epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1\nAlice noodt!’ ‘I’r ald too’ wopp on all dicaicn allan. ‘Herireg6 he thet, Sly thath thithe stemarlking ho vovy@ourk tha trout bese lowge of then onttrothe bemede and steand-ent cabe ating,’ sare ingooverm at hibd aadilly, a the Kidow hof aninctisen.’ ‘It’t armer clowhen-naPr, the ttay salid,’ swhipe cast--ong po seoun on verke#-aningss. ‘NU) ehen frer veen. Einiladd a waid. ‘ef am miee noscong figrrey.’ O. I ingil if the on in couc ise san mir chars tite defned ast tor, tolp the stith os thnle it’ce, bke meas caigrighinge srat we: opr het an a sikke l O?’ dook fro in Ole. ‘Wh mat fraolfy ‘Andint mulyougs hott! the emeld hand pale to the stamped byoug,’qule. ‘Them the doundy ind inourkntiy? 6O’ Ha windE, Shisttrine fo mas she cich Pout bely leashidk Vignte. You) Itis. ‘Xtilitherinde tho seigh the wor =NS@D1E TDE--* Your!’ the nould sas on I. Rut wer thon’’ the bos a foy he Gemy to satedtid foun erten apead dutice nows en in fon ffisting saing an ha her taes all trowech thael h. Ded noce he to\n---\nTrain for 28 steps\nEpoch 1/10\n28/28 [==============================] - 1s 19ms/step - loss: 2.1142\nEpoch 2/10\n28/28 [==============================] - 0s 15ms/step - loss: 2.0725\nEpoch 3/10\n28/28 [==============================] - 0s 15ms/step - loss: 2.0334\nEpoch 4/10\n28/28 [==============================] - 0s 16ms/step - loss: 1.9964\nEpoch 5/10\n28/28 [==============================] - 0s 16ms/step - loss: 1.9625\nEpoch 6/10\n28/28 [==============================] - 0s 17ms/step - loss: 1.9306\nEpoch 7/10\n28/28 [==============================] - 0s 16ms/step - loss: 1.9018\nEpoch 8/10\n28/28 [==============================] - 0s 15ms/step - loss: 1.8751\nEpoch 9/10\n28/28 [==============================] - 0s 17ms/step - loss: 1.8502\nEpoch 10/10\n28/28 [==============================] - 0s 16ms/step - loss: 1.8264\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\nWARNING:tensorflow:Unresolved object in checkpoint: (root)._training_endpoints\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).embedding_layer.embeddings\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense_layer.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense_layer.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).embedding_layer.embeddings\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense_layer.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense_layer.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.bias\nWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\nafter epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2\nAlice When gans dean?” browe!’ ‘In I daght-mang. Prjicttmn, with I were come rimessess, as lakj!’ <U s. Thet ax a munt apcove this afooratifusle--prothing this?’ caid goter are wing tlo down’t onios gowler, ‘would wish hey or of fropser toor, Alice us wGstingled NIo ruppto picempy wopive. No they ‘Go graint!’ Alice hore voumentr eever of to like that or the’s the ofray, Meall muck aboteen an frivistor a Sibegn’t hip grat’t a five-bedl sued, be word on,’ shers beting olled brObchor: but hadde; at this guther on, ‘Whard her andertion and said thougk in that I could. ‘thend in pull has a‘bontan there sere=lice to dow longter breeme now. ‘I houldied expenwilled And, bow no parks: br! Taught to know, but aplearny threy Loog!’ Alice said the betif ATifus her wees is whenbery chtlle wenys troul.’ Alice nesbyon--’ sake coars--and thes at you rae exambengt of brore it crupter frood asterm!” ‘I hac she chare he the way caight so sens.’ ‘Ther bresteryed.’ Thee-pantset--ang grow hear treener the retued \n---\nTrain for 28 steps\nEpoch 1/10\n28/28 [==============================] - 1s 20ms/step - loss: 1.8036\nEpoch 2/10\n28/28 [==============================] - 0s 16ms/step - loss: 1.7838\nEpoch 3/10\n28/28 [==============================] - 0s 17ms/step - loss: 1.7649\nEpoch 4/10\n28/28 [==============================] - 0s 17ms/step - loss: 1.7471\nEpoch 5/10\n28/28 [==============================] - 0s 17ms/step - loss: 1.7289\nEpoch 6/10\n28/28 [==============================] - 0s 16ms/step - loss: 1.7148\nEpoch 7/10\n28/28 [==============================] - 0s 17ms/step - loss: 1.6989\nEpoch 8/10\n28/28 [==============================] - 0s 17ms/step - loss: 1.6843\nEpoch 9/10\n28/28 [==============================] - 1s 18ms/step - loss: 1.6711\nEpoch 10/10\n28/28 [==============================] - 0s 15ms/step - loss: 1.6578\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\nWARNING:tensorflow:Unresolved object in checkpoint: (root)._training_endpoints\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).embedding_layer.embeddings\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense_layer.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense_layer.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).embedding_layer.embeddings\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense_layer.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense_layer.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.bias\nWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\nafter epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3\nAlice can a treach the thunked ence her kis a have onfore the Red Queen of this his for A4 be devorse. ‘WIN Mangeling crisplably be notcharsh it in up, be that Haking her his wenbly flLice: ‘that she warden a tlaar!’ Faret for the quily. ‘“have as a pept a ever2/ with head greath as Proked=\"\"/z:h'/<p>/A> Canges canftersally coopes.” ‘bryingsthing to knowing to promentered the Red EBLEEBUS?. O hal this if she mull son if, of andly dcor,’ said, but the way: I try if her ‘Immag the cany began’s, she last,’ said becat off’t in anm, how heres, I the Sheoughtpese?’ And houldn’t pacl,”’ HA-D dither is, morrul, when alling add up be all with for sall numny efots youghe asken for sond. Alide. ‘Dis horvenborigh criedd to she knough the chive if the minkenecs coragerss! Who in a youm on! what was can’t sear to hets of on then as my with oft.’ ‘They VERrould fad the quight to but not on ought buttlaging frot mive misurys, and thener dare of just thaking King sigeved, asks, and frick Project doned seed: \n---\nTrain for 28 steps\nEpoch 1/10\n28/28 [==============================] - 1s 20ms/step - loss: 1.6457\nEpoch 2/10\n28/28 [==============================] - 0s 17ms/step - loss: 1.6353\nEpoch 3/10\n28/28 [==============================] - 0s 17ms/step - loss: 1.6228\nEpoch 4/10\n28/28 [==============================] - 0s 16ms/step - loss: 1.6126\nEpoch 5/10\n28/28 [==============================] - 0s 17ms/step - loss: 1.6035\nEpoch 6/10\n28/28 [==============================] - 1s 18ms/step - loss: 1.5935\nEpoch 7/10\n28/28 [==============================] - 0s 18ms/step - loss: 1.5841\nEpoch 8/10\n28/28 [==============================] - 0s 18ms/step - loss: 1.5761\nEpoch 9/10\n28/28 [==============================] - 0s 17ms/step - loss: 1.5659\nEpoch 10/10\n28/28 [==============================] - 1s 18ms/step - loss: 1.5573\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\nWARNING:tensorflow:Unresolved object in checkpoint: (root)._training_endpoints\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).embedding_layer.embeddings\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense_layer.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense_layer.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).embedding_layer.embeddings\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense_layer.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense_layer.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.bias\nWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\nafter epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4\nAlice chorse, and the feare to det as you’ll her my desh.’ ‘It’s in a many opene, ‘(he had twould thow.’ ‘I know cousele an, wenty, try ham Citsing a WAS IN a wor dos tnicn jucked like, she said, shay gir,’ Alice wait feet un, a> a couldn’t was brook at tone on in dithing ew, you here, and of quinn! Now, inders!’ Befe retts goundred now with a of. ‘You knothe. ‘Of eary that blease not Gecuched been yet, and a toor yOUN AK?’ Alice is prisar, while you know.’ ‘I was conforts coid calls sive again the must other hay for AME stardons hire!’ The didn’t suppingses, they. ‘No know, I’m again. ‘I to gets to cried, ard anding in vistream than withere and thre punt on hid with one and for vintery.ax. A law works as she said, as a cla face on lasty pur’t meait, igher an fix this on to the Queen wit hung. Be a than than acountied you cords thather fill is was scraared her head wind his ear?’ said All she excloss?’ he was again about nernow: Alice had like that broplying of. The I Poars Alice was by must\n---\nTrain for 28 steps\nEpoch 1/10\n28/28 [==============================] - 1s 19ms/step - loss: 1.5500\nEpoch 2/10\n28/28 [==============================] - 0s 16ms/step - loss: 1.5428\nEpoch 3/10\n28/28 [==============================] - 0s 18ms/step - loss: 1.5345\nEpoch 4/10\n28/28 [==============================] - 0s 16ms/step - loss: 1.5278\nEpoch 5/10\n28/28 [==============================] - 0s 16ms/step - loss: 1.5198\nEpoch 6/10\n28/28 [==============================] - 0s 16ms/step - loss: 1.5138\nEpoch 7/10\n28/28 [==============================] - 0s 16ms/step - loss: 1.5068\nEpoch 8/10\n28/28 [==============================] - 0s 15ms/step - loss: 1.5005\nEpoch 9/10\n28/28 [==============================] - 0s 17ms/step - loss: 1.4952\nEpoch 10/10\n28/28 [==============================] - 0s 16ms/step - loss: 1.4885\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\nWARNING:tensorflow:Unresolved object in checkpoint: (root)._training_endpoints\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).embedding_layer.embeddings\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense_layer.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense_layer.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).rnn_layer.cell.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).embedding_layer.embeddings\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense_layer.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense_layer.bias\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.recurrent_kernel\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).rnn_layer.cell.bias\nWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\nafter epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5\nAlice as the bad, don’t hind had gesersolis prover the more which you couldn’t kevereginly glasswant), Kittying a sive a look!’ has fell he VOER thoughe’r quets, and sort. It “DOTER Wolo conself. ‘I’ll settly.’ ‘And a looking and brop care a pawe. But she somethouge This hargain porition counts,’ the Rn; *’ ‘Wen was to mese down thauthily lash to look?’ she had here way.’ And cair--ous (on remarking or to him at in but its may coment o if them of it the listle mived at from in again. ‘In a poirumert as not ther vanteruan: (she lound the hood sings full fally, this it in take of that she copything to derelvence, she was loum. So you ketten’t had crighed. So you know what what, you couldn’t get: ‘there was gon ining in as, when The THID now set out of that’s jure past to the time noed to set body. Compen from uperial fee it want it for found thick.,’ ‘I truh,’ Alice fel himself so now, she was anxing not liger, ‘he’ve one neck. (‘This tobution IN=Dumpty?’ she was it’s the Red Queen come.<//p> \n---\n"
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "for i in range(num_epochs // 10):\n",
    "   model.fit(\n",
    "       dataset.repeat(),\n",
    "       epochs=10,\n",
    "       steps_per_epoch=steps_per_epoch\n",
    "       # callbacks=[checkpoint_callback, tensorboard_callback]\n",
    "   )\n",
    "   checkpoint_file = os.path.join(\n",
    "       CHECKPOINT_DIR, \"model_epoch_{:d}\".format(i+1))\n",
    "   model.save_weights(checkpoint_file)\n",
    "   # create generative model using the trained model so far\n",
    "   gen_model = CharGenModel(vocab_size, seq_length, embedding_dim)\n",
    "   gen_model.load_weights(checkpoint_file)\n",
    "   gen_model.build(input_shape=(1, seq_length))\n",
    "   print(\"after epoch: {:d}\".format(i+1)*10)\n",
    "   print(generate_text(gen_model, \"Alice \", char2idx, idx2char))\n",
    "   print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitvenvvirtualenved65712175164bb8ae5452abd92f3ec5",
   "display_name": "Python 3.6.9 64-bit ('.venv': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}